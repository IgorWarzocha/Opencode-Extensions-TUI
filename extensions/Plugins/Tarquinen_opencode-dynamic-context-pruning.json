{
  "id": "Tarquinen_opencode-dynamic-context-pruning",
  "name": "Dynamic Context Pruning",
  "description": "Dynamic context pruning plugin for OpenCode - intelligently manages conversation context to optimize token usage",
  "readme": "# Dynamic Context Pruning Plugin\n\n[![npm version](https://img.shields.io/npm/v/@tarquinen/opencode-dcp.svg)](https://www.npmjs.com/package/@tarquinen/opencode-dcp)\n\nAutomatically reduces token usage in OpenCode by removing obsolete tool outputs from conversation history.\n\n![DCP in action](dcp-demo3.png)\n\n## Installation\n\nAdd to your OpenCode config:\n\n```jsonc\n// opencode.jsonc\n{\n  \"plugin\": [\"@tarquinen/opencode-dcp@0.4.2\"],\n  \"experimental\": {\n    \"primary_tools\": [\"prune\"]\n  }\n}\n```\n\nThe `experimental.primary_tools` setting ensures the `prune` tool is only available to the primary agent (not subagents).\n\nWhen a new version is available, DCP will show a toast notification. Update by changing the version number in your config.\n\nRestart OpenCode. The plugin will automatically start optimizing your sessions.\n\n## How Pruning Works\n\nDCP uses two complementary techniques:\n\n**Automatic Deduplication** — Silently identifies repeated tool calls (e.g., reading the same file multiple times) and keeps only the most recent output. Runs on every request with zero LLM cost.\n\n**AI Analysis** — Uses a language model to semantically analyze conversation context and identify tool outputs that are no longer relevant to the current task. More thorough but incurs LLM cost. Configurable via `strategies`.\n\n## Context Pruning Tool\n\nWhen `strategies.onTool` is enabled, DCP exposes a `prune` tool to Opencode that the AI can call to trigger pruning on demand.\n\nWhen `nudge_freq` is enabled, injects reminders (every `nudge_freq` tool results) prompting the AI to consider pruning when appropriate.\n\n## How It Works\n\nYour session history is never modified. DCP replaces pruned outputs with a placeholder before sending requests to your LLM.\n\n## Impact on Prompt Caching\n\nLLM providers like Anthropic and OpenAI cache prompts based on exact prefix matching. When DCP prunes a tool output, it changes the message content, which invalidates cached prefixes from that point forward.\n\n**Trade-off:** You lose some cache read benefits but gain larger token savings from reduced context size. In most cases, the token savings outweigh the cache miss cost—especially in long sessions where context bloat becomes significant.\n\n## Configuration\n\nDCP uses its own config file (`~/.config/opencode/dcp.jsonc` or `.opencode/dcp.jsonc`), created automatically on first run.\n\n### Options\n\n| Option | Default | Description |\n|--------|---------|-------------|\n| `enabled` | `true` | Enable/disable the plugin |\n| `debug` | `false` | Log to `~/.config/opencode/logs/dcp/` |\n| `model` | (session) | Model for analysis (e.g., `\"anthropic/claude-haiku-4-5\"`) |\n| `showModelErrorToasts` | `true` | Show notifications on model fallback |\n| `showUpdateToasts` | `true` | Show notifications when a new version is available |\n| `strictModelSelection` | `false` | Only run AI analysis with session or configured model (disables fallback models) |\n| `pruning_summary` | `\"detailed\"` | `\"off\"`, `\"minimal\"`, or `\"detailed\"` |\n| `nudge_freq` | `10` | How often to remind AI to prune (lower = more frequent) |\n| `protectedTools` | `[\"task\", \"todowrite\", \"todoread\", \"prune\"]` | Tools that are never pruned |\n| `strategies.onIdle` | `[\"ai-analysis\"]` | Strategies for automatic pruning |\n| `strategies.onTool` | `[\"ai-analysis\"]` | Strategies when AI calls `prune` |\n\n**Strategies:** `\"ai-analysis\"` uses LLM to identify prunable outputs. Empty array disables that trigger. Deduplication runs automatically on every request.\n\n```jsonc\n{\n  \"enabled\": true,\n  \"strategies\": {\n    \"onIdle\": [\"ai-analysis\"],\n    \"onTool\": [\"ai-analysis\"]\n  },\n  \"protectedTools\": [\"task\", \"todowrite\", \"todoread\", \"prune\"]\n}\n```\n\n### Config Precedence\n\nSettings are merged in order: **Defaults** → **Global** (`~/.config/opencode/dcp.jsonc`) → **Project** (`.opencode/dcp.jsonc`). Each level overrides the previous, so project settings take priority over global, which takes priority over defaults.\n\nRestart OpenCode after making config changes.\n\n## License\n\nMIT\n",
  "author": "Tarquinen",
  "author_url": "https://github.com/Tarquinen",
  "repository_url": "https://github.com/Tarquinen/opencode-dynamic-context-pruning",
  "category": "Plugins",
  "install_command": "npm install @tarquinen/opencode-dcp",
  "install_method": "npm"
}